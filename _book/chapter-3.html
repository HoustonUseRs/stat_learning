<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Notes on: Introduction to Statistical Learning</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Notes and solutions on ISLR">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Notes on: Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notes and solutions on ISLR" />
  <meta name="github-repo" content="HoustonUseRs/stat_learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Notes on: Introduction to Statistical Learning" />
  
  <meta name="twitter:description" content="Notes and solutions on ISLR" />
  

<meta name="author" content="Houston R Users">


<meta name="date" content="2017-02-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter-2.html">
<link rel="next" href="chapter-4.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

true

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes on: Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter-3" class="section level1">
<h1><span class="header-section-number">2</span> Chapter 3</h1>
<div id="notes-1" class="section level2">
<h2><span class="header-section-number">2.1</span> Notes</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)

x1 =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>)
x2 =<span class="st"> </span><span class="fl">0.5</span>*x1 +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)/<span class="dv">10</span>

<span class="co">#   b0  b1      b2        error</span>
y =<span class="st"> </span><span class="dv">2</span> +<span class="st"> </span><span class="dv">2</span> *x1 +<span class="st"> </span><span class="fl">0.3</span>*x2 +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)

<span class="kw">plot</span>(x1, x2)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x1, x2)</code></pre></div>
<pre><code>## [1] 0.8351212</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_out =<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x1 +<span class="st"> </span>x2)
<span class="kw">summary</span>(lm_out)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8311 -0.7273 -0.0537  0.6338  2.3359 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.1305     0.2319   9.188 7.61e-15 ***
## x1            1.4396     0.7212   1.996   0.0487 *  
## x2            1.0097     1.1337   0.891   0.3754    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.056 on 97 degrees of freedom
## Multiple R-squared:  0.2088, Adjusted R-squared:  0.1925 
## F-statistic:  12.8 on 2 and 97 DF,  p-value: 1.164e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># using x1 only</span>
lm_x1 =<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x1)
<span class="kw">summary</span>(lm_x1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.89495 -0.66874 -0.07785  0.59221  2.45560 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.1124     0.2307   9.155 8.27e-15 ***
## x1            1.9759     0.3963   4.986 2.66e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.055 on 98 degrees of freedom
## Multiple R-squared:  0.2024, Adjusted R-squared:  0.1942 
## F-statistic: 24.86 on 1 and 98 DF,  p-value: 2.661e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># using x2 only</span>
lm_x2 =<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x2)
<span class="kw">summary</span>(lm_x2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.62687 -0.75156 -0.03598  0.72383  2.44890 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.3899     0.1949   12.26  &lt; 2e-16 ***
## x2            2.8996     0.6330    4.58 1.37e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.072 on 98 degrees of freedom
## Multiple R-squared:  0.1763, Adjusted R-squared:  0.1679 
## F-statistic: 20.98 on 1 and 98 DF,  p-value: 1.366e-05</code></pre>
</div>
<div id="we-have-a-issue-of-collinearity" class="section level2">
<h2><span class="header-section-number">2.2</span> we have a issue of collinearity</h2>
<p>SE of B1 full model: SE of estimate when we use both seperately, the SE are lower. <a href="http://stats.stackexchange.com/questions/113733/what-is-the-difference-between-collinearity-and-interaction">what-is-the-difference-between-collinearity-and-interaction</a></p>
<p>Collinearity is a statistical phenomenon in which two or more predictor variables in a multiple regression model are highly correlated, meaning that one can be linearly predicted from the others with a non-trivial degree of accuracy. In this situation the coefficient estimates of the multiple regression may change erratically in response to small changes in the model or the data. Collinearity does not reduce the predictive power or reliability of the model as a whole, at least within the sample data themselves; it only affects calculations regarding individual predictors. That is, a multiple regression model with correlated predictors can indicate how well the entire bundle of predictors predicts the outcome variable, but it may not give valid results about any individual predictor, or about which predictors are redundant with respect to others.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x1 =<span class="st"> </span><span class="kw">c</span>(x1, <span class="fl">0.1</span>)
x2 =<span class="st"> </span><span class="kw">c</span>(x2, <span class="fl">0.8</span>)

y =<span class="st"> </span><span class="kw">c</span>(y, <span class="dv">6</span>)
lm_out =<span class="st"> </span><span class="kw">lm</span>( y ~<span class="st"> </span>x1+x2)
<span class="kw">summary</span>(lm_out)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.73348 -0.69318 -0.05263  0.66385  2.30619 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.2267     0.2314   9.624 7.91e-16 ***
## x1            0.5394     0.5922   0.911  0.36458    
## x2            2.5146     0.8977   2.801  0.00614 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.075 on 98 degrees of freedom
## Multiple R-squared:  0.2188, Adjusted R-squared:  0.2029 
## F-statistic: 13.72 on 2 and 98 DF,  p-value: 5.564e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op =<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(lm_out, <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(op)


<span class="co"># try degrees of freedom</span>
<span class="kw">pt</span>(<span class="fl">1.996</span>, <span class="dt">df =</span> <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>) *<span class="st"> </span><span class="dv">2</span> </code></pre></div>
<pre><code>## [1] 0.04873763</code></pre>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pacman)
<span class="kw">p_load</span>(ISLR)
<span class="kw">p_load</span>(janitor, dplyr, broom)
<span class="kw">p_load</span>(ggplot2, cowplot, corrplot)</code></pre></div>
<div id="q6" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Q6</h3>
<p>Using (3.4), argue that in the case of simple linear regression, the least squares line always passes through the point <span class="math inline">\((\overline{x},\overline{y})\)</span>.</p>
<p><em>The least square line equation is <span class="math inline">\(y = \hat{\beta}_0 + \hat{\beta}_1x\)</span>, so if we substitute <span class="math inline">\(\overline{x}\)</span> for <span class="math inline">\(x\)</span> we obtain <span class="math display">\[y = \hat{\beta}_0 + \hat{\beta}_1\overline{x} = \overline{y} - \hat{\beta}_1\overline{x} + \hat{\beta}_1\overline{x} = \overline{y}.\]</span> We may conclude that the least square line passes through the point <span class="math inline">\((\overline{x},\overline{y})\)</span>.</em></p>
</div>
<div id="q9" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Q9</h3>
<p>This question involves the use of multiple linear regression on the “Auto” data set.</p>
<ol style="list-style-type: lower-alpha">
<li>Produce a scatterplot matrix which include all the variables in the data set.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># use lowercase</span>
auto =<span class="st"> </span>Auto
<span class="kw">pairs</span>(auto)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-7-1.png" width="1152" /></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Compute the matrix of correlations between the variables using the function cor(). You will need to exclude the “name” variable, which is qualitative.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">select</span>(auto, -name) %&gt;%<span class="st"> </span><span class="kw">cor</span>() %&gt;%<span class="st"> </span><span class="kw">corrplot</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div id="c-use-the-lm-function-to-perform-a-multiple-linear-regression-with-mpg-as-the-response-and-all-other-variables-except-name-as-the-predictors.-use-the-summary-function-to-print-the-results.-comment-on-the-output.-for-instance" class="section level4">
<h4><span class="header-section-number">2.2.2.1</span> (c) Use the lm() function to perform a multiple linear regression with “mpg” as the response and all other variables except “name” as the predictors. Use the summary() function to print the results. Comment on the output. For instance :</h4>
<p><em>i. Is there a relationship between the predictors and the response ?</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit2 &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span>. -<span class="st"> </span>name, <span class="dt">data =</span> auto)

<span class="kw">summary</span>(fit2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ . - name, data = auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.5903 -2.1565 -0.1169  1.8690 13.0604 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -17.218435   4.644294  -3.707  0.00024 ***
## cylinders     -0.493376   0.323282  -1.526  0.12780    
## displacement   0.019896   0.007515   2.647  0.00844 ** 
## horsepower    -0.016951   0.013787  -1.230  0.21963    
## weight        -0.006474   0.000652  -9.929  &lt; 2e-16 ***
## acceleration   0.080576   0.098845   0.815  0.41548    
## year           0.750773   0.050973  14.729  &lt; 2e-16 ***
## origin         1.426141   0.278136   5.127 4.67e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.328 on 384 degrees of freedom
## Multiple R-squared:  0.8215, Adjusted R-squared:  0.8182 
## F-statistic: 252.4 on 7 and 384 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_fit =<span class="st"> </span><span class="kw">tidy</span>(fit2);df_fit</code></pre></div>
<pre><code>##           term      estimate    std.error statistic      p.value
## 1  (Intercept) -17.218434622 4.6442941494 -3.707438 2.401841e-04
## 2    cylinders  -0.493376319 0.3232823146 -1.526147 1.277965e-01
## 3 displacement   0.019895644 0.0075150792  2.647430 8.444649e-03
## 4   horsepower  -0.016951144 0.0137868914 -1.229512 2.196328e-01
## 5       weight  -0.006474043 0.0006520478 -9.928787 7.874953e-21
## 6 acceleration   0.080575838 0.0988449567  0.815174 4.154780e-01
## 7         year   0.750772678 0.0509731223 14.728795 3.055983e-39
## 8       origin   1.426140495 0.2781360924  5.127492 4.665681e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=R+summary+2.2e-16</span>
fit_fstat =<span class="st"> </span><span class="kw">summary</span>(fit2)$fstatistic
<span class="kw">pf</span>(<span class="dt">q =</span> fit_fstat[<span class="dv">1</span>], 
   <span class="dt">df1 =</span> fit_fstat[<span class="dv">2</span>], <span class="dt">df2 =</span> fit_fstat[<span class="dv">3</span>], 
   <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>##         value 
## 2.037106e-139</code></pre>
<p>We can answer this question by again testing the hypothesis <span class="math inline">\(H_0 : \beta_i = 0\ \forall i\)</span>. The p-value corresponding to the F-statistic is <code>r</code>, this indicates a clear evidence of a relationship between “mpg” and the other predictors.</p>
<ol start="2" style="list-style-type: lower-roman">
<li>Which predictors appear to have a statistically significant relationship to the response ?</li>
</ol>
<p><em>We can answer this question by checking the p-values associated with each predictor’s t-statistic. We may conclude that all predictors are statistically significant except “cylinders”, “horsepower” and “acceleration”.</em></p>
<ol start="3" style="list-style-type: lower-roman">
<li>What does the coefficient for the “year” variable suggest ?</li>
</ol>
<p><em>The coefficient ot the “year” variable suggests that the average effect of an increase of 1 year is an increase of 0.7507727 in “mpg” (all other predictors remaining constant). In other words, cars become more fuel efficient every year by almost 1 mpg / year.</em></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Use the plot() function to produce diagnostic plots of the linear regression fit. Comment on any problems you see with the fit. Do the residual plots suggest any unusually large outliers? Does the leverage plots identify any observations with unusually high leverages ?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(fit2)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p><em>As before, the plot of residuals versus fitted values indicates the presence of mild non linearity in the data. The plot of standardized residuals versus leverage indicates the presence of a few outliers (higher than 2 or lower than -2) and one high leverage point (point 14).</em></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Use the * and : symbols to fit linear regression models with interaction effects. Do any interactions appear to be statistically significant ?</li>
</ol>
<p><em>From the correlation matrix, we obtained the two highest correlated pairs and used them in picking interaction effects.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit3 &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span>cylinders *<span class="st"> </span>displacement +<span class="st"> </span>displacement *<span class="st"> </span>weight, <span class="dt">data =</span> <span class="kw">select</span>(auto, -name))
<span class="kw">summary</span>(fit3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ cylinders * displacement + displacement * 
##     weight, data = select(auto, -name))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.2934  -2.5184  -0.3476   1.8399  17.7723 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             5.262e+01  2.237e+00  23.519  &lt; 2e-16 ***
## cylinders               7.606e-01  7.669e-01   0.992    0.322    
## displacement           -7.351e-02  1.669e-02  -4.403 1.38e-05 ***
## weight                 -9.888e-03  1.329e-03  -7.438 6.69e-13 ***
## cylinders:displacement -2.986e-03  3.426e-03  -0.872    0.384    
## displacement:weight     2.128e-05  5.002e-06   4.254 2.64e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.103 on 386 degrees of freedom
## Multiple R-squared:  0.7272, Adjusted R-squared:  0.7237 
## F-statistic: 205.8 on 5 and 386 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>From the p-values, we can see that the interaction between displacement and weight is statistically signifcant, while the interactiion between cylinders and displacement is not.</em></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Try a few different transformations of the variables, such as <span class="math inline">\(\log{X}\)</span>, <span class="math inline">\(\sqrt{X}\)</span>, <span class="math inline">\(X^2\)</span>. Comment on your findings.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(auto$horsepower, auto$mpg)
<span class="kw">plot</span>((auto$horsepower)^<span class="fl">0.5</span>, auto$mpg)
<span class="kw">plot</span>(<span class="kw">sqrt</span>(auto$horsepower), auto$mpg)
<span class="kw">plot</span>(<span class="kw">log</span>(auto$horsepower), auto$mpg)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p><em>We limit ourselves to examining “horsepower” as sole predictor. It seems that the log transformation gives the most linear looking plot.</em></p>
</div>
</div>
<div id="q10" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Q10</h3>
<p>This question should be answered using the “Carseats” data set.</p>
<ul>
<li>Sales: Unit sales (in thousands) at each location</li>
<li>CompPrice: Price charged by competitor at each location</li>
<li>Income: Community income level (in thousands of dollars)</li>
<li>Advertising: Local advertising budget for company at each location (in thousands of dollars)</li>
<li>Population: Population size in region (in thousands)</li>
<li>Price: Price company charges for car seats at each site</li>
<li>ShelveLoc: A factor with levels Bad, Good and Medium indicating the quality of the shelving location for the car seats at each site</li>
<li>Age: Average age of the local population</li>
<li>Education: Education level at each location</li>
<li>Urban: A factor with levels No and Yes to indicate whether the store is in an urban or rural location</li>
<li>US: A factor with levels No and Yes to indicate whether the store is in the US or not</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Fit a multiple regression model to predict “Sales” using “Price”, “Urban” and “US”.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Carseats)
carseats =<span class="st"> </span><span class="kw">clean_names</span>(Carseats)

fit3 &lt;-<span class="st"> </span><span class="kw">lm</span>(sales ~<span class="st"> </span>price +<span class="st"> </span>urban +<span class="st"> </span>us, <span class="dt">data =</span> carseats)
<span class="kw">summary</span>(fit3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ price + urban + us, data = carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9206 -1.6220 -0.0564  1.5786  7.0581 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.043469   0.651012  20.036  &lt; 2e-16 ***
## price       -0.054459   0.005242 -10.389  &lt; 2e-16 ***
## urbanYes    -0.021916   0.271650  -0.081    0.936    
## usYes        1.200573   0.259042   4.635 4.86e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.472 on 396 degrees of freedom
## Multiple R-squared:  0.2393, Adjusted R-squared:  0.2335 
## F-statistic: 41.52 on 3 and 396 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Provide an interpretation of each coefficient in the model. Be careful - some of the variables in the model are qualitative !</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># negative effect of price</span>
<span class="kw">sprintf</span>(<span class="st">&quot;For a $1 increase in price average sales change by %s&quot;</span>, 
        <span class="kw">summary</span>(fit3)$coef[<span class="dv">2</span>, <span class="dv">1</span>] *<span class="st"> </span><span class="dv">1000</span>)</code></pre></div>
<pre><code>## [1] &quot;For a $1 increase in price average sales change by -54.4588491775822&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># effect of urban</span>
<span class="kw">sprintf</span>(<span class="st">&quot;Average sales in urban are %s compared to non-urban&quot;</span>, 
        <span class="kw">summary</span>(fit3)$coef[<span class="dv">3</span>, <span class="dv">1</span>] *<span class="st"> </span><span class="dv">1000</span>)</code></pre></div>
<pre><code>## [1] &quot;Average sales in urban are -21.916150814141 compared to non-urban&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># effect of US</span>
<span class="kw">sprintf</span>(<span class="st">&quot;Average sales in US are %s more than non-US&quot;</span>, 
        <span class="kw">summary</span>(fit3)$coef[<span class="dv">4</span>, <span class="dv">1</span>] *<span class="st"> </span><span class="dv">1000</span>)</code></pre></div>
<pre><code>## [1] &quot;Average sales in US are 1200.57269779412 more than non-US&quot;</code></pre>
<ul>
<li>The coefficient of the “Price” variable may be interpreted by saying that the average effect of a price increase of 1 dollar is a decrease of <code>r</code> units in sales all other predictors remaining fixed.</li>
</ul>
<p>The coefficient of the “Urban” variable may be interpreted by saying that on average the unit sales in urban location are 21.9161508 units less than in rural location all other predictors remaining fixed.</p>
<p>The coefficient of the “US” variable may be interpreted by saying that on average the unit sales in a US store are 1200.5726978 units more than in a non US store all other predictors remaining fixed.*</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Write out the model in equation form, being careful to handle the qualitative variables properly.</li>
</ol>
<p>The model may be written as <span class="math display">\[Sales = 13.0434689 + (-0.0544588)\times Price + (-0.0219162)\times Urban + (1.2005727)\times US + \varepsilon\]</span></p>
<p>with <span class="math inline">\(Urban = 1\)</span> if the store is in an urban location and <span class="math inline">\(0\)</span> if not, and <span class="math inline">\(US = 1\)</span> if the store is in the US and <span class="math inline">\(0\)</span> if not.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>For which of the predictors can you reject the null hypothesis <span class="math inline">\(H_0 : \beta_j = 0\)</span> ?</li>
</ol>
<p><em>We can reject the null hypothesis for the “Price” and “US” variables.</em></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit4 &lt;-<span class="st"> </span><span class="kw">lm</span>(sales ~<span class="st"> </span>price +<span class="st"> </span>us, <span class="dt">data =</span> carseats)
<span class="kw">summary</span>(fit4)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sales ~ price + us, data = carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9269 -1.6286 -0.0574  1.5766  7.0515 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.03079    0.63098  20.652  &lt; 2e-16 ***
## price       -0.05448    0.00523 -10.416  &lt; 2e-16 ***
## usYes        1.19964    0.25846   4.641 4.71e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.469 on 397 degrees of freedom
## Multiple R-squared:  0.2393, Adjusted R-squared:  0.2354 
## F-statistic: 62.43 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="6" style="list-style-type: lower-alpha">
<li>How well do the models in (a) and (e) fit the data ?</li>
</ol>
<p><em>The <span class="math inline">\(R^2\)</span> for the smaller model is marginally better than for the bigger model. Essentially about 23.9262888% of the variability is explained by the model.</em></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Using the model from (e), obtain 95% confidence intervals for the coefficient(s).</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(fit4)</code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept) 11.79032020 14.27126531
## price       -0.06475984 -0.04419543
## usYes        0.69151957  1.70776632</code></pre>
<ol start="8" style="list-style-type: lower-alpha">
<li>Is there evidence of outliers or high leverage observations in the model from (e) ?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(fit4)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>The plot of standardized residuals versus leverage indicates the presence of a few outliers (higher than 2 or lower than -2) and some leverage points as some points exceed <span class="math inline">\((p + 1)/n\)</span> (0.01).</p>
</div>
<div id="q11" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Q11</h3>
<p>In this problem we will investigate the t-statistic for the null hypothesis <span class="math inline">\(H_0 : \beta = 0\)</span> in simple linear regression without an intercept. To begin, we generate a predictor <span class="math inline">\(x\)</span> and a response <span class="math inline">\(y\)</span> as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)
<span class="co"># y = 2X + error</span>
y &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>x +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Perform a simple linear regression of <span class="math inline">\(y\)</span> onto <span class="math inline">\(x\)</span>, without an intercept. Report the coefficient estimate <span class="math inline">\(\hat{\beta}\)</span>, the standard error of this coefficient estimate, and the t-statistic and p-value associated with the null hypothesis <span class="math inline">\(H_0\)</span>. Comment on these results.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># do not use intercept</span>
fit5 &lt;-<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x +<span class="st"> </span><span class="dv">0</span>)
<span class="kw">summary</span>(fit5)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x + 0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.9154 -0.6472 -0.1771  0.5056  2.3109 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(&gt;|t|)    
## x   1.9939     0.1065   18.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9586 on 99 degrees of freedom
## Multiple R-squared:  0.7798, Adjusted R-squared:  0.7776 
## F-statistic: 350.7 on 1 and 99 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># default is to use an intercept</span>
fit6 &lt;-<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x)
<span class="kw">summary</span>(fit6)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8768 -0.6138 -0.1395  0.5394  2.3462 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.03769    0.09699  -0.389    0.698    
## x            1.99894    0.10773  18.556   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9628 on 98 degrees of freedom
## Multiple R-squared:  0.7784, Adjusted R-squared:  0.7762 
## F-statistic: 344.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>According to the summary above, we have a value of 1.9938761 for <span class="math inline">\(\hat{\beta}\)</span>, a value of 0.1064767 for the standard error, a value of 18.7259319 for the t-statistic and a value of 2.642196910^{-34} for the p-value. The small p-value allows us to reject <span class="math inline">\(H_0\)</span>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Now perform a simple linear regression of <span class="math inline">\(x\)</span> onto <span class="math inline">\(y\)</span>, without an intercept. Report the coefficient estimate <span class="math inline">\(\hat{\beta}\)</span>, the standard error of this coefficient estimate, and the t-statistic and p-value associated with the null hypothesis <span class="math inline">\(H_0\)</span>. Comment on these results.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit6 &lt;-<span class="st"> </span><span class="kw">lm</span>(x ~<span class="st"> </span>y +<span class="st"> </span><span class="dv">0</span>)
<span class="kw">summary</span>(fit6)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = x ~ y + 0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.8699 -0.2368  0.1030  0.2858  0.8938 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(&gt;|t|)    
## y  0.39111    0.02089   18.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4246 on 99 degrees of freedom
## Multiple R-squared:  0.7798, Adjusted R-squared:  0.7776 
## F-statistic: 350.7 on 1 and 99 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>According to the summary above, we have a value of 0.3911145 for <span class="math inline">\(\hat{\beta}\)</span>, a value of 0.0208863 for the standard error, a value of 18.7259319 for the t-statistic and a value of 2.642196910^{-34} for the p-value. The small p-value allows us to reject <span class="math inline">\(H_0\)</span>.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>What is the relationship between the results obtained in (a) and (b) ?</li>
</ol>
<p><em>We obtain the same value for the t-statistic and consequently the same value for the corresponding p-value. Both results in (a) and (b) reflect the same line created in (a). In other words, <span class="math inline">\(y = 2x + \varepsilon\)</span> could also be written <span class="math inline">\(x = 0.5(y − \varepsilon)\)</span>.</em></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>For the regrssion of <span class="math inline">\(Y\)</span> onto <span class="math inline">\(X\)</span> without an intercept, the t-statistic for <span class="math inline">\(H_0 : \beta = 0\)</span> takes the form <span class="math inline">\(\hat{\beta}/SE(\hat{\beta})\)</span>, where <span class="math inline">\(\hat{\beta}\)</span> is given by (3.38), and where <span class="math display">\[SE(\hat{\beta}) = \sqrt{\frac{\sum_{i=1}^n(y_i - x_i\hat{\beta})^2}{(n - 1)\sum_{i=1}^nx_i^2}}.\]</span> Show algebraically, and confirm numerically in R, that the t-statistic can be written as <span class="math display">\[\frac{\sqrt{n - 1}\sum_{i=1}^nx_iy_i}{\sqrt{(\sum_{i=1}^nx_i^2)(\sum_{i=1}^ny_i^2) - (\sum_{i=1}^nx_iy_i)}}.\]</span></li>
</ol>
<p><em>We have <span class="math display">\[t = \frac{\sum_ix_iy_y/\sum_jx_j^2}{\sqrt{\sum_i(y_i - x_i\hat{\beta})^2/(n - 1)\sum_jx_j^2}} = \frac{\sqrt{n - 1}\sum_ix_iy_i}{\sqrt{\sum_jx_j^2\sum_i(y_i - x_i\sum_jx_jy_j/\sum_jx_j^2)^2}} = \frac{\sqrt{n - 1}\sum_ix_iy_i}{\sqrt{(\sum_jx_j^2)(\sum_jy_j^2) - (\sum_jx_jy_j)}}.\]</span> Now let’s verify this result numerically.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
t &lt;-<span class="st"> </span><span class="kw">sqrt</span>(n -<span class="st"> </span><span class="dv">1</span>)*(x %*%<span class="st"> </span>y)/<span class="kw">sqrt</span>(<span class="kw">sum</span>(x^<span class="dv">2</span>) *<span class="st"> </span><span class="kw">sum</span>(y^<span class="dv">2</span>) -<span class="st"> </span>(x %*%<span class="st"> </span>y)^<span class="dv">2</span>)
<span class="kw">as.numeric</span>(t)</code></pre></div>
<pre><code>## [1] 18.72593</code></pre>
<p><em>We may see that the t above is exactly the t-statistic given in the summary of “fit6”.</em></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Using the results from (d), argue that the t-statistic for the regression of <span class="math inline">\(y\)</span> onto <span class="math inline">\(x\)</span> is the same t-statistic for the regression of <span class="math inline">\(x\)</span> onto <span class="math inline">\(y\)</span>.</li>
</ol>
<p><em>It is easy to see that if we replace <span class="math inline">\(x_i\)</span> by <span class="math inline">\(y_i\)</span> in the formula for the t-statistic, the result would be the same.</em></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>In R, show that when regression is performed with an intercept, the t-statistic for <span class="math inline">\(H_0 : \beta_1 = 0\)</span> is the same for the regression of <span class="math inline">\(y\)</span> onto <span class="math inline">\(x\)</span> as it is the regression of <span class="math inline">\(x\)</span> onto <span class="math inline">\(y\)</span>.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit7 &lt;-<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x)
<span class="kw">summary</span>(fit7)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8768 -0.6138 -0.1395  0.5394  2.3462 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.03769    0.09699  -0.389    0.698    
## x            1.99894    0.10773  18.556   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9628 on 98 degrees of freedom
## Multiple R-squared:  0.7784, Adjusted R-squared:  0.7762 
## F-statistic: 344.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit8 &lt;-<span class="st"> </span><span class="kw">lm</span>(x ~<span class="st"> </span>y)
<span class="kw">summary</span>(fit8)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = x ~ y)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.90848 -0.28101  0.06274  0.24570  0.85736 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.03880    0.04266    0.91    0.365    
## y            0.38942    0.02099   18.56   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4249 on 98 degrees of freedom
## Multiple R-squared:  0.7784, Adjusted R-squared:  0.7762 
## F-statistic: 344.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>It is again easy to see that the t-statistic for “fit7” and “fit8” are both equal to 18.5555993.</em></p>
<blockquote>
<p>END</p>
</blockquote>

</div>
</div>
<div id="problem-8-a" class="section level2">
<h2><span class="header-section-number">2.3</span> Problem 8 (a)</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
<span class="kw">attach</span>(Auto)</code></pre></div>
<pre><code>## The following object is masked from package:ggplot2:
## 
##     mpg</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit&lt;-<span class="kw">lm</span>(mpg~horsepower)
<span class="kw">summary</span>(lm.fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ horsepower)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.5710  -3.2592  -0.3435   2.7630  16.9240 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 39.935861   0.717499   55.66   &lt;2e-16 ***
## horsepower  -0.157845   0.006446  -24.49   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.906 on 390 degrees of freedom
## Multiple R-squared:  0.6059, Adjusted R-squared:  0.6049 
## F-statistic: 599.7 on 1 and 390 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol style="list-style-type: lower-roman">
<li>Yes</li>
<li>mpg is -0.158 times horsepower</li>
<li>negative</li>
</ol>
<div id="prediction-and-intervals" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Prediction and intervals</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(lm.fit,<span class="kw">data.frame</span>(<span class="dt">horsepower=</span>(<span class="kw">c</span>(<span class="dv">98</span>))),<span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 24.46708 23.97308 24.96108</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(lm.fit,<span class="kw">data.frame</span>(<span class="dt">horsepower=</span>(<span class="kw">c</span>(<span class="dv">98</span>))),<span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</code></pre></div>
<pre><code>##        fit     lwr      upr
## 1 24.46708 14.8094 34.12476</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Plots</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(horsepower,mpg)
<span class="kw">abline</span>(lm.fit,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Diagnostic plots</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lm.fit)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-27-1.png" width="672" /> Residuals are non linear. Few high leverage and high studentized residual(&gt;3) points</p>
</div>
</div>
<div id="problem-9" class="section level2">
<h2><span class="header-section-number">2.4</span> Problem 9</h2>
<ol style="list-style-type: lower-alpha">
<li>All plots</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(Auto)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-28-1.png" width="672" /> ## Correlation</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(Auto[-<span class="dv">9</span>])</code></pre></div>
<pre><code>##                     mpg  cylinders displacement horsepower     weight
## mpg           1.0000000 -0.7776175   -0.8051269 -0.7784268 -0.8322442
## cylinders    -0.7776175  1.0000000    0.9508233  0.8429834  0.8975273
## displacement -0.8051269  0.9508233    1.0000000  0.8972570  0.9329944
## horsepower   -0.7784268  0.8429834    0.8972570  1.0000000  0.8645377
## weight       -0.8322442  0.8975273    0.9329944  0.8645377  1.0000000
## acceleration  0.4233285 -0.5046834   -0.5438005 -0.6891955 -0.4168392
## year          0.5805410 -0.3456474   -0.3698552 -0.4163615 -0.3091199
## origin        0.5652088 -0.5689316   -0.6145351 -0.4551715 -0.5850054
##              acceleration       year     origin
## mpg             0.4233285  0.5805410  0.5652088
## cylinders      -0.5046834 -0.3456474 -0.5689316
## displacement   -0.5438005 -0.3698552 -0.6145351
## horsepower     -0.6891955 -0.4163615 -0.4551715
## weight         -0.4168392 -0.3091199 -0.5850054
## acceleration    1.0000000  0.2903161  0.2127458
## year            0.2903161  1.0000000  0.1815277
## origin          0.2127458  0.1815277  1.0000000</code></pre>
</div>
<div id="fiting-a-linear-model" class="section level2">
<h2><span class="header-section-number">2.5</span> Fiting a linear model</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit&lt;-<span class="kw">lm</span>(mpg~.-name,<span class="dt">data=</span>Auto)
<span class="kw">summary</span>(lm.fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ . - name, data = Auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.5903 -2.1565 -0.1169  1.8690 13.0604 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -17.218435   4.644294  -3.707  0.00024 ***
## cylinders     -0.493376   0.323282  -1.526  0.12780    
## displacement   0.019896   0.007515   2.647  0.00844 ** 
## horsepower    -0.016951   0.013787  -1.230  0.21963    
## weight        -0.006474   0.000652  -9.929  &lt; 2e-16 ***
## acceleration   0.080576   0.098845   0.815  0.41548    
## year           0.750773   0.050973  14.729  &lt; 2e-16 ***
## origin         1.426141   0.278136   5.127 4.67e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.328 on 384 degrees of freedom
## Multiple R-squared:  0.8215, Adjusted R-squared:  0.8182 
## F-statistic: 252.4 on 7 and 384 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>Displacement, weight, year and origin has a relation to the mpg</li>
<li>Year, don’t know</li>
</ul>
<p>Residual plots</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lm.fit)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>The residuals are non linear. The leverage for point 14 is high.</p>
<p>Linear model with interaction term</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm2.fit&lt;-<span class="kw">lm</span>(mpg~.-name+displacement:weight+displacement:year,<span class="dt">data=</span>Auto)
<span class="kw">summary</span>(lm2.fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ . - name + displacement:weight + displacement:year, 
##     data = Auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.6499 -1.5864 -0.0841  1.3300 13.2550 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         -4.038e+01  7.511e+00  -5.376 1.33e-07 ***
## cylinders            4.220e-01  2.885e-01   1.463 0.144382    
## displacement         1.287e-01  3.687e-02   3.492 0.000536 ***
## horsepower          -4.215e-02  1.204e-02  -3.502 0.000517 ***
## weight              -9.700e-03  7.075e-04 -13.709  &lt; 2e-16 ***
## acceleration         8.766e-02  8.485e-02   1.033 0.302210    
## year                 1.215e+00  8.861e-02  13.714  &lt; 2e-16 ***
## origin               5.159e-01  2.526e-01   2.042 0.041798 *  
## displacement:weight  2.004e-05  2.225e-06   9.010  &lt; 2e-16 ***
## displacement:year   -2.597e-03  4.651e-04  -5.584 4.48e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.854 on 382 degrees of freedom
## Multiple R-squared:  0.8694, Adjusted R-squared:  0.8663 
## F-statistic: 282.6 on 9 and 382 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lm2.fit)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
</div>
<div id="problem-10" class="section level2">
<h2><span class="header-section-number">2.6</span> Problem 10</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit1&lt;-<span class="kw">lm</span>(Sales~Price+Urban+US,<span class="dt">data=</span>Carseats)
<span class="kw">summary</span>(lm.fit1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Sales ~ Price + Urban + US, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9206 -1.6220 -0.0564  1.5786  7.0581 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.043469   0.651012  20.036  &lt; 2e-16 ***
## Price       -0.054459   0.005242 -10.389  &lt; 2e-16 ***
## UrbanYes    -0.021916   0.271650  -0.081    0.936    
## USYes        1.200573   0.259042   4.635 4.86e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.472 on 396 degrees of freedom
## Multiple R-squared:  0.2393, Adjusted R-squared:  0.2335 
## F-statistic: 41.52 on 3 and 396 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit2&lt;-<span class="kw">lm</span>(Sales~Price+US,<span class="dt">data=</span>Carseats)
<span class="kw">summary</span>(lm.fit2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Sales ~ Price + US, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9269 -1.6286 -0.0574  1.5766  7.0515 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.03079    0.63098  20.652  &lt; 2e-16 ***
## Price       -0.05448    0.00523 -10.416  &lt; 2e-16 ***
## USYes        1.19964    0.25846   4.641 4.71e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.469 on 397 degrees of freedom
## Multiple R-squared:  0.2393, Adjusted R-squared:  0.2354 
## F-statistic: 62.43 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lm.fit2)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-33-1.png" width="672" /> Studentized residual</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">predict</span>(lm.fit2), <span class="kw">rstudent</span>(lm.fit2))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
</div>
<div id="confidence-interval" class="section level2">
<h2><span class="header-section-number">2.7</span> Confidence Interval</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(lm.fit2)</code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept) 11.79032020 14.27126531
## Price       -0.06475984 -0.04419543
## USYes        0.69151957  1.70776632</code></pre>
</div>
<div id="problem-11a" class="section level2">
<h2><span class="header-section-number">2.8</span> Problem 11a</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
x&lt;-<span class="kw">rnorm</span>(<span class="dv">100</span>)
y&lt;-<span class="dv">2</span>*x+<span class="kw">rnorm</span>(<span class="dv">100</span>)
lm.fit3&lt;-<span class="kw">lm</span>(y~x<span class="dv">+0</span>)
<span class="kw">summary</span>(lm.fit3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x + 0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.9154 -0.6472 -0.1771  0.5056  2.3109 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(&gt;|t|)    
## x   1.9939     0.1065   18.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9586 on 99 degrees of freedom
## Multiple R-squared:  0.7798, Adjusted R-squared:  0.7776 
## F-statistic: 350.7 on 1 and 99 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="problem-11b" class="section level2">
<h2><span class="header-section-number">2.9</span> Problem 11b</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit4&lt;-<span class="kw">lm</span>(x~y<span class="dv">+0</span>)
<span class="kw">summary</span>(lm.fit4)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = x ~ y + 0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.8699 -0.2368  0.1030  0.2858  0.8938 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(&gt;|t|)    
## y  0.39111    0.02089   18.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4246 on 99 degrees of freedom
## Multiple R-squared:  0.7798, Adjusted R-squared:  0.7776 
## F-statistic: 350.7 on 1 and 99 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Problem 13a-d</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)
eps &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dt">sd=</span><span class="kw">sqrt</span>(.<span class="dv">25</span>))
y &lt;-<span class="st"> </span>-<span class="dv">1</span><span class="fl">+0.5</span>*x+eps
<span class="kw">library</span>(ggplot2)
<span class="co"># data frame to make ggplot easier</span>
dt &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y=</span>y,<span class="dt">x=</span>x)
p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>dt,<span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y))
p+<span class="kw">geom_point</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Problem 13e</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit13e &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x)
<span class="kw">summary</span>(lm.fit13e)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.37090 -0.28070 -0.00874  0.33987  0.92421 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.97578    0.04955  -19.69   &lt;2e-16 ***
## x            0.55311    0.04813   11.49   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4953 on 98 degrees of freedom
## Multiple R-squared:  0.574,  Adjusted R-squared:  0.5697 
## F-statistic: 132.1 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Problem 13f : Creating plots</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>dt,<span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y))
p+<span class="kw">geom_point</span>()+<span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&#39;lm&#39;</span>,<span class="dt">formula=</span>y~x)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>Problem 13g: Fitting a <span class="math inline">\(x^2\)</span> term to the linear regression</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit13g &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x+<span class="kw">I</span>(x^<span class="dv">2</span>))
<span class="kw">summary</span>(lm.fit13g)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x + I(x^2))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.37065 -0.27658 -0.01063  0.32886  0.96560 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.96391    0.05986 -16.104   &lt;2e-16 ***
## x            0.55096    0.04872  11.309   &lt;2e-16 ***
## I(x^2)      -0.01114    0.03120  -0.357    0.722    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4975 on 97 degrees of freedom
## Multiple R-squared:  0.5746, Adjusted R-squared:  0.5658 
## F-statistic: 65.51 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Since the p value is high, it is not possible to reject the null hypothesis. So the additional quadratic term does not improve the model fit</p>
<p>Problem 13h-i : Decreasing the noise in the data. i.e decrease the variance in the eps term</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">epsl &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dt">sd=</span><span class="fl">0.1</span>)
yl &lt;-<span class="st"> </span>-<span class="dv">1</span><span class="fl">+0.5</span>*x+epsl
epsm &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dt">sd=</span><span class="fl">0.9</span>)
ym &lt;-<span class="st"> </span>-<span class="dv">1</span><span class="fl">+0.5</span>*x+epsm

lm.fit13h &lt;-<span class="st"> </span><span class="kw">lm</span>(yl~x)
lm.fit13i &lt;-<span class="st"> </span><span class="kw">lm</span>(ym~x)

<span class="kw">summary</span>(lm.fit13h)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = yl ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.29007 -0.06856 -0.00725  0.06562  0.37907 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.00401    0.01176  -85.41   &lt;2e-16 ***
## x            0.50336    0.01142   44.08   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1175 on 98 degrees of freedom
## Multiple R-squared:  0.952,  Adjusted R-squared:  0.9515 
## F-statistic:  1943 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm.fit13i)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ym ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.24241 -0.59495 -0.05686  0.65945  1.88746 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.03902    0.08736 -11.894  &lt; 2e-16 ***
## x            0.46480    0.08485   5.478 3.33e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8732 on 98 degrees of freedom
## Multiple R-squared:  0.2344, Adjusted R-squared:  0.2266 
## F-statistic:    30 on 1 and 98 DF,  p-value: 3.335e-07</code></pre>
</div>
<div id="problem-13j-comparing-the-confidence-intervals" class="section level2">
<h2><span class="header-section-number">2.10</span> Problem 13j : Comparing the confidence intervals</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Original </span>
<span class="kw">confint</span>(lm.fit13e)</code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) -1.0741052 -0.8774448
## x            0.4575975  0.6486210</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Lesser noise</span>
<span class="kw">confint</span>(lm.fit13h)</code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) -1.027341 -0.9806850
## x            0.480699  0.5260179</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># More noise</span>
<span class="kw">confint</span>(lm.fit13i)</code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) -1.2123830 -0.8656630
## x            0.2964127  0.6331946</code></pre>
<p>Problem 14a</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
x1 &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>)

x2 &lt;-<span class="st"> </span><span class="fl">0.5</span>*x1+<span class="kw">rnorm</span> (<span class="dv">100</span>)/<span class="dv">10</span>
y &lt;-<span class="st"> </span><span class="dv">2+2</span>*x1<span class="fl">+0.3</span>*x2+<span class="kw">rnorm</span> (<span class="dv">100</span>)</code></pre></div>
<p>Problem 14b</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x1,x2)</code></pre></div>
<pre><code>## [1] 0.8351212</code></pre>
<p>Scatter</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x1,x2)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-46-1.png" width="672" /> Problem 14c : Fitting a linear model Equation <span class="math inline">\(y=2+2x_1+0.3x_2+\epsilon,x_2=0.5x_1\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit14c &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x1+x2)
<span class="kw">summary</span>(lm.fit14c)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8311 -0.7273 -0.0537  0.6338  2.3359 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.1305     0.2319   9.188 7.61e-15 ***
## x1            1.4396     0.7212   1.996   0.0487 *  
## x2            1.0097     1.1337   0.891   0.3754    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.056 on 97 degrees of freedom
## Multiple R-squared:  0.2088, Adjusted R-squared:  0.1925 
## F-statistic:  12.8 on 2 and 97 DF,  p-value: 1.164e-05</code></pre>
<p>Estimated <span class="math inline">\(\beta_0,\beta_1,\beta_2=2.13,1.5,1\)</span> Actual <span class="math inline">\(\beta_0,\beta_1,\beta_2=2,2,0.3\)</span></p>
<p>x2 has high p value, so the null hypothesis<span class="math inline">\(\beta_2=0\)</span> cannot be rejected</p>
<p>Problem 14d: Fitting only for x1</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit14d &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x1)
<span class="kw">summary</span>(lm.fit14d)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.89495 -0.66874 -0.07785  0.59221  2.45560 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.1124     0.2307   9.155 8.27e-15 ***
## x1            1.9759     0.3963   4.986 2.66e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.055 on 98 degrees of freedom
## Multiple R-squared:  0.2024, Adjusted R-squared:  0.1942 
## F-statistic: 24.86 on 1 and 98 DF,  p-value: 2.661e-06</code></pre>
<p>p-value and F static proves that the null hypothesis can be rejected</p>
<p>Problem 14e: Fitting for x2 alone</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit14e &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x2)
<span class="kw">summary</span>(lm.fit14e)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.62687 -0.75156 -0.03598  0.72383  2.44890 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.3899     0.1949   12.26  &lt; 2e-16 ***
## x2            2.8996     0.6330    4.58 1.37e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.072 on 98 degrees of freedom
## Multiple R-squared:  0.1763, Adjusted R-squared:  0.1679 
## F-statistic: 20.98 on 1 and 98 DF,  p-value: 1.366e-05</code></pre>
<p>p-value and F static proves that the null hypothesis can be rejected</p>
<p>Problem 14f : The results contradict due to the linearity between x1 and x2. This can be examined by looking at the correlation matrix. It is better to look at the VIF.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;car&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     recode</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># For the fit with X1 and X2</span>
<span class="kw">vif</span>(lm.fit14c)</code></pre></div>
<pre><code>##       x1       x2 
## 3.304993 3.304993</code></pre>
<p>Not sure about how to interpret these values.</p>
<p>Problem 14g:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x1 &lt;-<span class="st"> </span><span class="kw">c</span>(x1,<span class="fl">0.1</span>)
x2 &lt;-<span class="st"> </span><span class="kw">c</span>(x2,<span class="fl">0.8</span>)
y &lt;-<span class="st"> </span><span class="kw">c</span>(y,<span class="dv">6</span>)

lm.fit14g1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x1+x2)
lm.fit14g2 &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x1)
lm.fit14g3 &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x2)

<span class="kw">summary</span>(lm.fit14g1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.73348 -0.69318 -0.05263  0.66385  2.30619 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.2267     0.2314   9.624 7.91e-16 ***
## x1            0.5394     0.5922   0.911  0.36458    
## x2            2.5146     0.8977   2.801  0.00614 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.075 on 98 degrees of freedom
## Multiple R-squared:  0.2188, Adjusted R-squared:  0.2029 
## F-statistic: 13.72 on 2 and 98 DF,  p-value: 5.564e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm.fit14g2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8897 -0.6556 -0.0909  0.5682  3.5665 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.2569     0.2390   9.445 1.78e-15 ***
## x1            1.7657     0.4124   4.282 4.29e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.111 on 99 degrees of freedom
## Multiple R-squared:  0.1562, Adjusted R-squared:  0.1477 
## F-statistic: 18.33 on 1 and 99 DF,  p-value: 4.295e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm.fit14g3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.64729 -0.71021 -0.06899  0.72699  2.38074 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.3451     0.1912  12.264  &lt; 2e-16 ***
## x2            3.1190     0.6040   5.164 1.25e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.074 on 99 degrees of freedom
## Multiple R-squared:  0.2122, Adjusted R-squared:  0.2042 
## F-statistic: 26.66 on 1 and 99 DF,  p-value: 1.253e-06</code></pre>
<p>It is an outlier. Checking with diagnostic plots</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lm.fit14g1)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lm.fit14g2)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-52-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lm.fit14g3)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-52-3.png" width="672" /></p>
<p>Looks like an outlier, in the second case <span class="math inline">\(y\equiv x1\)</span>, since the studentized residual is over 3.</p>
</div>
<div id="problem-15a-plots-and-linear-regression-to-each-variable" class="section level2">
<h2><span class="header-section-number">2.11</span> Problem 15a : Plots and linear regression to each variable</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plots</span>
<span class="kw">pairs</span>(Boston)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">DF &lt;-<span class="st"> </span>Boston
<span class="kw">summary</span>(DF)</code></pre></div>
<pre><code>##       crim                zn             indus            chas        
##  Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  
##  1st Qu.: 0.08204   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  
##  Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  
##  Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  
##  3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  
##  Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  
##       nox               rm             age              dis        
##  Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  
##  1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  
##  Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  
##  Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  
##  3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  
##  Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  
##       rad              tax           ptratio          black       
##  Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  
##  1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  
##  Median : 5.000   Median :330.0   Median :19.05   Median :391.44  
##  Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  
##  3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  
##  Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  
##      lstat            medv      
##  Min.   : 1.73   Min.   : 5.00  
##  1st Qu.: 6.95   1st Qu.:17.02  
##  Median :11.36   Median :21.20  
##  Mean   :12.65   Mean   :22.53  
##  3rd Qu.:16.95   3rd Qu.:25.00  
##  Max.   :37.97   Max.   :50.00</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Not a good way to do it </span>
<span class="kw">attach</span>(Boston)
<span class="kw">summary</span>(<span class="kw">lm</span>(crim~zn))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ zn)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -4.429 -4.222 -2.620  1.250 84.523 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.45369    0.41722  10.675  &lt; 2e-16 ***
## zn          -0.07393    0.01609  -4.594 5.51e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.435 on 504 degrees of freedom
## Multiple R-squared:  0.04019,    Adjusted R-squared:  0.03828 
## F-statistic:  21.1 on 1 and 504 DF,  p-value: 5.506e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~indus))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ indus)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -11.972  -2.698  -0.736   0.712  81.813 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -2.06374    0.66723  -3.093  0.00209 ** 
## indus        0.50978    0.05102   9.991  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.866 on 504 degrees of freedom
## Multiple R-squared:  0.1653, Adjusted R-squared:  0.1637 
## F-statistic: 99.82 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~chas))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ chas)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.738 -3.661 -3.435  0.018 85.232 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   3.7444     0.3961   9.453   &lt;2e-16 ***
## chas         -1.8928     1.5061  -1.257    0.209    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.597 on 504 degrees of freedom
## Multiple R-squared:  0.003124,   Adjusted R-squared:  0.001146 
## F-statistic: 1.579 on 1 and 504 DF,  p-value: 0.2094</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~nox))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ nox)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.371  -2.738  -0.974   0.559  81.728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -13.720      1.699  -8.073 5.08e-15 ***
## nox           31.249      2.999  10.419  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.81 on 504 degrees of freedom
## Multiple R-squared:  0.1772, Adjusted R-squared:  0.1756 
## F-statistic: 108.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~rm))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ rm)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.604 -3.952 -2.654  0.989 87.197 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   20.482      3.365   6.088 2.27e-09 ***
## rm            -2.684      0.532  -5.045 6.35e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.401 on 504 degrees of freedom
## Multiple R-squared:  0.04807,    Adjusted R-squared:  0.04618 
## F-statistic: 25.45 on 1 and 504 DF,  p-value: 6.347e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~age))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ age)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.789 -4.257 -1.230  1.527 82.849 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.77791    0.94398  -4.002 7.22e-05 ***
## age          0.10779    0.01274   8.463 2.85e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.057 on 504 degrees of freedom
## Multiple R-squared:  0.1244, Adjusted R-squared:  0.1227 
## F-statistic: 71.62 on 1 and 504 DF,  p-value: 2.855e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~dis))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ dis)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.708 -4.134 -1.527  1.516 81.674 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   9.4993     0.7304  13.006   &lt;2e-16 ***
## dis          -1.5509     0.1683  -9.213   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.965 on 504 degrees of freedom
## Multiple R-squared:  0.1441, Adjusted R-squared:  0.1425 
## F-statistic: 84.89 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~rad))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ rad)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.164  -1.381  -0.141   0.660  76.433 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -2.28716    0.44348  -5.157 3.61e-07 ***
## rad          0.61791    0.03433  17.998  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.718 on 504 degrees of freedom
## Multiple R-squared:  0.3913, Adjusted R-squared:   0.39 
## F-statistic: 323.9 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~tax))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ tax)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.513  -2.738  -0.194   1.065  77.696 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -8.528369   0.815809  -10.45   &lt;2e-16 ***
## tax          0.029742   0.001847   16.10   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.997 on 504 degrees of freedom
## Multiple R-squared:  0.3396, Adjusted R-squared:  0.3383 
## F-statistic: 259.2 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~ptratio))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ ptratio)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -7.654 -3.985 -1.912  1.825 83.353 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -17.6469     3.1473  -5.607 3.40e-08 ***
## ptratio       1.1520     0.1694   6.801 2.94e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.24 on 504 degrees of freedom
## Multiple R-squared:  0.08407,    Adjusted R-squared:  0.08225 
## F-statistic: 46.26 on 1 and 504 DF,  p-value: 2.943e-11</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~black))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ black)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.756  -2.299  -2.095  -1.296  86.822 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 16.553529   1.425903  11.609   &lt;2e-16 ***
## black       -0.036280   0.003873  -9.367   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.946 on 504 degrees of freedom
## Multiple R-squared:  0.1483, Adjusted R-squared:  0.1466 
## F-statistic: 87.74 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~lstat))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ lstat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.925  -2.822  -0.664   1.079  82.862 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.33054    0.69376  -4.801 2.09e-06 ***
## lstat        0.54880    0.04776  11.491  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.664 on 504 degrees of freedom
## Multiple R-squared:  0.2076, Adjusted R-squared:  0.206 
## F-statistic:   132 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(crim~medv))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ medv)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.071 -4.022 -2.343  1.298 80.957 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 11.79654    0.93419   12.63   &lt;2e-16 ***
## medv        -0.36316    0.03839   -9.46   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.934 on 504 degrees of freedom
## Multiple R-squared:  0.1508, Adjusted R-squared:  0.1491 
## F-statistic: 89.49 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Observations For chas, the p value is high.</p>
</div>
<div id="problem-15b-fitting-a-multiple-linear-regression" class="section level2">
<h2><span class="header-section-number">2.12</span> Problem 15b: Fitting a multiple linear regression</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
lm.fit15b &lt;-<span class="st"> </span><span class="kw">lm</span>(crim~.,<span class="dt">data =</span> Boston)
<span class="kw">summary</span>(lm.fit15b)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ ., data = Boston)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.924 -2.120 -0.353  1.019 75.051 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  17.033228   7.234903   2.354 0.018949 *  
## zn            0.044855   0.018734   2.394 0.017025 *  
## indus        -0.063855   0.083407  -0.766 0.444294    
## chas         -0.749134   1.180147  -0.635 0.525867    
## nox         -10.313535   5.275536  -1.955 0.051152 .  
## rm            0.430131   0.612830   0.702 0.483089    
## age           0.001452   0.017925   0.081 0.935488    
## dis          -0.987176   0.281817  -3.503 0.000502 ***
## rad           0.588209   0.088049   6.680 6.46e-11 ***
## tax          -0.003780   0.005156  -0.733 0.463793    
## ptratio      -0.271081   0.186450  -1.454 0.146611    
## black        -0.007538   0.003673  -2.052 0.040702 *  
## lstat         0.126211   0.075725   1.667 0.096208 .  
## medv         -0.198887   0.060516  -3.287 0.001087 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.439 on 492 degrees of freedom
## Multiple R-squared:  0.454,  Adjusted R-squared:  0.4396 
## F-statistic: 31.47 on 13 and 492 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Observations : The null hypothesis can only be rejected for dis,rad,blac,zn,indus,medv</p>
<p>Checking linear model fit</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lm.fit15b)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-56-1.png" width="672" /><img src="bookdown-demo_files/figure-html/unnamed-chunk-56-2.png" width="672" /><img src="bookdown-demo_files/figure-html/unnamed-chunk-56-3.png" width="672" /><img src="bookdown-demo_files/figure-html/unnamed-chunk-56-4.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(Boston)</code></pre></div>
<pre><code>## The following objects are masked from Boston (pos = 3):
## 
##     age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio,
##     rad, rm, tax, zn</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~zn))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~indus))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~chas))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~nox))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~rm))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~age))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~dis))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~rad))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~tax))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~ptratio))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~black))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~lstat))[<span class="dv">2</span>],
<span class="kw">coefficients</span>(<span class="kw">lm</span>(crim~medv))[<span class="dv">2</span>])
b &lt;-<span class="st"> </span><span class="kw">coefficients</span>(lm.fit15b)[<span class="dv">2</span>:<span class="dv">14</span>]
<span class="kw">plot</span>(b~a)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">13</span>),b/a)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-57-2.png" width="672" /></p>
<p>Checking the VIF</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)
<span class="kw">vif</span>(lm.fit15b)</code></pre></div>
<pre><code>##       zn    indus     chas      nox       rm      age      dis      rad 
## 2.325094 3.987753 1.094326 4.551563 2.258113 3.100801 4.289041 7.158834 
##      tax  ptratio    black    lstat     medv 
## 9.195495 1.984489 1.369741 3.561476 3.772856</code></pre>
<p>Fitting a non linear model to the third power.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(Boston)</code></pre></div>
<pre><code>## The following objects are masked from Boston (pos = 3):
## 
##     age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio,
##     rad, rm, tax, zn</code></pre>
<pre><code>## The following objects are masked from Boston (pos = 4):
## 
##     age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio,
##     rad, rm, tax, zn</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.fit15d &lt;-<span class="st"> </span><span class="kw">lm</span>(crim~dis+<span class="kw">I</span>(dis^<span class="dv">2</span>)+<span class="kw">I</span>(dis^<span class="dv">3</span>)+rad+<span class="kw">I</span>(rad^<span class="dv">2</span>)+<span class="kw">I</span>(rad^<span class="dv">3</span>)+black+<span class="kw">I</span>(black^<span class="dv">2</span>)+<span class="kw">I</span>(black^<span class="dv">3</span>)+zn+<span class="kw">I</span>(zn^<span class="dv">2</span>)+<span class="kw">I</span>(zn^<span class="dv">3</span>)+medv+<span class="kw">I</span>(medv^<span class="dv">2</span>)+<span class="kw">I</span>(medv^<span class="dv">3</span>))
<span class="kw">summary</span>(lm.fit15d)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = crim ~ dis + I(dis^2) + I(dis^3) + rad + I(rad^2) + 
##     I(rad^3) + black + I(black^2) + I(black^3) + zn + I(zn^2) + 
##     I(zn^3) + medv + I(medv^2) + I(medv^3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.846  -1.610  -0.062   1.126  70.953 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.507e+01  4.364e+00  10.327  &lt; 2e-16 ***
## dis         -5.852e+00  1.621e+00  -3.611 0.000337 ***
## I(dis^2)     1.041e+00  3.137e-01   3.318 0.000973 ***
## I(dis^3)    -5.379e-02  1.792e-02  -3.001 0.002827 ** 
## rad          4.388e-01  9.537e-01   0.460 0.645645    
## I(rad^2)    -4.780e-02  1.359e-01  -0.352 0.725086    
## I(rad^3)     1.831e-03  4.184e-03   0.438 0.661801    
## black       -2.964e-02  4.185e-02  -0.708 0.479179    
## I(black^2)   4.181e-05  2.214e-04   0.189 0.850282    
## I(black^3)   4.201e-08  3.243e-07   0.130 0.897005    
## zn          -5.036e-02  8.785e-02  -0.573 0.566727    
## I(zn^2)      1.254e-03  2.866e-03   0.438 0.661828    
## I(zn^3)     -8.868e-06  2.292e-05  -0.387 0.698971    
## medv        -3.711e+00  4.186e-01  -8.865  &lt; 2e-16 ***
## I(medv^2)    1.260e-01  1.620e-02   7.778 4.39e-14 ***
## I(medv^3)   -1.321e-03  1.905e-04  -6.938 1.26e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.853 on 490 degrees of freedom
## Multiple R-squared:  0.5508, Adjusted R-squared:  0.537 
## F-statistic: 40.05 on 15 and 490 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>rad is ‘interesting’</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter-4.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03a_notes.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
